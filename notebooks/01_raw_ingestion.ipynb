{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc2047ef-5cef-4dd9-a18a-30ba61bc6e29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 01_raw_ingestion\n",
    "Purpose: Ingest CSV sample files into Bronze (Delta) using PySpark.\n",
    "Author: Janak\n",
    "Date: 2025-11-26\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa990d54-d448-44e0-9dc5-e5c93be944a5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Setup & Imports"
    }
   },
   "outputs": [],
   "source": [
    "# Setup: adjust paths if needed\n",
    "dbfs_sample_dir = \"/FileStore/data/sample\"  # Databricks path exposed under /dbfs/FileStore/data/sample\n",
    "bronze_base = \"/tmp/delta/bronze\"          # Delta Bronze base path (change to /mnt/.. in prod)\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1293b48-d696-46d8-beb3-90a5ce06f2d5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Helper function (ingest CSV to Delta)"
    }
   },
   "outputs": [],
   "source": [
    "# Ingest helper\n",
    "def ingest_csv_to_delta_databricks(filename: str, table_name: str, input_dir: str=dbfs_sample_dir, bronze_base_path: str=bronze_base):\n",
    "    input_path = f\"/dbfs{input_dir}/{filename}\" if input_dir.startswith(\"/\") else f\"/dbfs/{input_dir}/{filename}\"\n",
    "    delta_path = f\"{bronze_base_path}/{table_name}\"\n",
    "    print(f\"Reading {input_path} -> writing Delta at {delta_path}\")\n",
    "    df = spark.read.option(\"header\", True).option(\"inferSchema\", False).csv(input_path)\n",
    "    # to be safe: coerce strings then write\n",
    "    df.write.format(\"delta\").mode(\"overwrite\").save(delta_path)\n",
    "    return df, delta_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63f8e91c-c46c-409a-aec8-1ccd48545f6e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Ingest all sample files"
    }
   },
   "outputs": [],
   "source": [
    "files_to_ingest = [\n",
    "    (\"orders.csv\", \"orders\"),\n",
    "    (\"customers.csv\", \"customers\"),\n",
    "    (\"products.csv\", \"products\"),\n",
    "    (\"payments.csv\", \"payments\"),\n",
    "    (\"inventory.csv\", \"inventory\"),\n",
    "]\n",
    "\n",
    "ingested = {}\n",
    "for fname, tname in files_to_ingest:\n",
    "    df, path = ingest_csv_to_delta_databricks(fname, tname)\n",
    "    ingested[tname] = {\"df\": df, \"delta_path\": path}\n",
    "    print(f\"Ingested {tname}: rows={df.count()}, cols={len(df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a04fb29-e1ca-4d4f-96f8-654b84cc13a7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Quick verification (show top rows)"
    }
   },
   "outputs": [],
   "source": [
    "for tname, meta in ingested.items():\n",
    "    print(\"----\", tname, \"----\")\n",
    "    display(meta[\"df\"].limit(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d9b4ea3-4280-42f1-b6c3-56777e2361e4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Register Delta paths as TempViews"
    }
   },
   "outputs": [],
   "source": [
    "from delta import *\n",
    "for tname, meta in ingested.items():\n",
    "    delta_path = meta[\"delta_path\"]\n",
    "    df_loaded = spark.read.format(\"delta\").load(delta_path)\n",
    "    df_loaded.createOrReplaceTempView(tname + \"_bronze\")\n",
    "    print(f\"Registered temp view: {tname}_bronze\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_raw_ingestion",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
