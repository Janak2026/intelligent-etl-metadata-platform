---

# ðŸ“¦ **requirements.txt (Full, Databricks-Compatible)**

```txt
# Core Python
python-dotenv

# API Layer
fastapi
uvicorn[standard]

# Data Validation & Utilities
pydantic
typing-extensions

# Unit Testing
pytest

# Delta Lake + Spark (cluster handles versions)
delta-spark
pyspark

# LLM / Embeddings (optional, safe for Databricks)
openai
tiktoken

# For future enhancements
pandas
numpy
```

---

# ðŸ“˜ Notes â€” Why these versions work

### âœ” `pyspark` & `delta-spark`

You do **not** pin versions â€” Databricks already installs the correct ones based on cluster runtime.

### âœ” `fastapi` + `uvicorn`

These run perfectly both:

* locally
* inside Databricks Jobs / external APIs

### âœ” `openai` + `tiktoken`

Used for LLM agent logic and embeddings.

### âœ” `pydantic`

For API models.

### âœ” `pytest`

For tests in `/tests`.

### âœ” No pinned versions

Pinned versions often conflict with Databricks runtime â€” this is the safest approach.

---
